\section{Overview}
\label{sec:overview}

We start with an overview of our approach to localizing type errors by
learning a model of the mistakes programmers actually make.
%
We formulate the problem of type error localization as a
\emph{supervised classification} problem.
%
A \emph{classification} problem entails learning a function that maps
inputs to a discrete set of output \emph{labels}, in contrast to
\emph{regression} where the output is typically a real number.
%
In a \emph{supervised} learning problem one is given a \emph{training}
set where the inputs and labels are known, and the task is to learn a
function that accurately maps the inputs to outputs and
\emph{generalizes} to new, yet-unseen inputs.

The key technical challenges we address are:
%
(1) formulating type error localization as a classification problem,
%
(2) generating correct labels for supervised learning, and
%
(3) presenting the predictions of the classifier in an intuitive manner.

\paragraph{\textbf{Challenge (1): How to represent programs?}}
The first and prime challenge we address is how to translate programs
into a format that machine learning techniques can understand.
%
Programs can be represented in many ways, from the raw text, to richly
structured abstract syntax trees and control-flow graphs, but none
of these representations are immediately amenable to machine learning.
%
Machine learning techniques typically take as input \emph{feature
vectors}, fixed-length vectors of real numbers where each element
represents some property of the input.
%
Thus, in order to apply machine learning to our problem we must
determine:
%
(1) what are interesting features of a program, and
%
(2) how can we represent a variable-size program as a fixed-length vector?

\paragraph{\textbf{Solution: Vectorized Abstract Syntax Trees}}
We start by assuming that we will extract features from the program's
abstract syntax tree (AST), a natural choice since the type checker
operates on ASTs.
%
An obvious set of interesting features is then the syntactic class of
each expression, \ie the classifier should be able to distinguish
between the |[]| and |+| expressions in \autoref{fig:sumList} because
they are formed by different constructors in the AST.
%
A programming language has a fixed set of AST elements, which suggests a
natural way to obtain fixed-size feature vectors: rather than translating
a program in a single feature vector, we translate it into a \emph{set} of
feature vectors, one for each expression in the program.
%
Thus, the |[]| and |+| expressions will each be given their own feature
vector, and we will ask the classifier to predict for each
\emph{independently} whether it should be blamed.

Of course, each expression occurs in some \emph{context}, and we would
like the classifier to be able make decisions based on the context as
well.
%
For example, we might expect that the recursive call |sumList t| is
unlikely to be at fault because |sumList| has a function type --- the
user may have called the wrong function or supplied the wrong argument,
but the application itself is probably correct.
%
Conversely, if the student wrote |h sumList t| (\ie forgot the |+|), we
might wish to blame the application rather than |h| because |h|
\emph{does not} have a function type.
%
Thus we \emph{extend} each expression's feature vector with
\emph{contextual features} of its parent and children.
%
These contextual features include the syntactic class of the neighboring
expressions, their inferred types, and, crucially, whether the
expression occurs in a minimal type error \emph{slice}.
%
A minimal type error slice of a program includes all expressions that
are necessary for the error to manifest and no more, this allows us to
tell the classifier which expressions could potentially be blamed ---
a change to an expression outside of the minimal slice cannot possibly
fix the type error.

\paragraph{\textbf{Challenge (2): What is the ``correct'' expression to blame?}}
As we saw in \autoref{fig:sumList}, type errors admit many different
fixes to different expressions, each resulting in a different program.
%
How is the type checker to judge which expressions are more likely to be
incorrect than others?
%
Prior work has enlisted expert users to manually judge ill-typed
programs and determine the ``correct'' fix, but this approach does not
scale well to a dataset large enough to perform machine learning.
%
Furthermore, while the expert user has intimate knowledge of the type
system, she cannot know what the student \emph{intended} to do.

\paragraph{\textbf{Solution: Use the students' subsequent fixes}}
%
Rather than relying on expert users, we allow our students to do the
work of assigning blame themselves.
%
Software development is an iterative process and our students will
eventually fix their own programs, perhaps after multiple ill-fated
attempts.
%
For each ill-typed program in our dataset, we find the first
\emph{subsequent} program that type checks and declare that to be the
fix.
%
From this pair of an ill-typed program and its fix, we can extract a
\emph{diff} of the abstract syntax trees.
%
For example, suppose our student fixed the |sumList| program in
\autoref{fig:sumList} by replacing |[]| with |0|, the diff would include
only the |[]| expression.
%
Thus we would determine that the |[]| expression (and \emph{not} the
|+|) is to blame for the error.


\paragraph{\textbf{Challenge (3): What should be presented to the user?}}
We now have the tools to train a classifier to predict, for each
expression in an ill-typed program, whether it should be changed.
%
But this is not yet particularly suitable as \emph{user feedback}.
%
A recent survey of developers by \citet{Kochhar2016-oc} found that
developers are unlikely to examine more than around five potentially
erroneous locations before falling back to manual debugging.
%
Thus, we should limit our predictions to a select few to be presented to
the user.

\paragraph{\textbf{Solution: Rank expressions by ``confidence''}}
Luckily, many machine learning classifiers produce not only a predicted
label, but also a metric that can be interpreted as the classifier's
\emph{confidence} in its prediction.
%
Thus, we \emph{rank} each expression by the classifier's confidence that
it should be changed, and present only the top-$k$ predictions to the
user (in practice $k=3$).



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
