\mysection{Overview} \label{sec:overview}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure}[t!]
\begin{minipage}{0.45\linewidth}
\begin{ecode}
  let rec sumList xs =
    match xs with
    | []   -> (*@\hlTree{\hlSherrloc{[]}}@*)
    | h::t -> h (*@\hlTree{+}@*) (*@\hlFix{sumList t}@*)
\end{ecode}
\end{minipage}
\begin{minipage}{0.49\linewidth}
\begin{verbatim}
File "sumList.ml", line 4, characters 16-25:
  This expression has type 'a list
  but an expression was expected of type int
\end{verbatim}
\end{minipage}
\caption{(left) An ill-typed \ocaml program that should sum the elements of a
  list, with highlights indicating three possible blame assignments based on:
  %
  (1) the \hlFix{\ocaml} compiler;
  %
  (2) the \hlSherrloc{fix} made by the programmer; and
  %
  (3) \hlTree{minimizing} the number of edits required.
  % The \underline{underlined} expressions are equally valid
  % locations to blame. The expression blamed by the \ocaml compiler
  % is in \textbf{bold}.
  %
  % FIXME: This bolding is ambiguous, because ``let rec'', ``match'' and
  % ``with'' are also bolded (by \\ecode)! You need to find another way to
  % highlight what ocaml is yelling about.
  %
  (right) The error reported by \ocaml.}
\label{fig:sumList}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Lets start with an overview of \toolname's
approach to localizing type errors by
collectively learning from the mistakes
programmers actually make.

\mypara{The Problem}
%
Consider the |sumList| program in
\autoref{fig:sumList}, written by
a student in an undergraduate
Programming Languages course.
%
The program is meant to add up the
integers in a list, but the student
has accidentally given the empty
list as the base case, rather than |0|.
%
The \ocaml compiler collects typing
constraints as it traverses the program,
and reports an error the moment it finds
an inconsistent constraint.
%
In this case it blames the recursive call
to |sumList|, complaining that |sumList|
returns a |list| where an |int| was
expected by the |+| operator.
%
This \emph{blame} assignment is inconsistent
with the programmer's intention and may
not be helpful debugging information to
a novice.

It may appear obvious to the reader that
|[]| is the correct expression to blame,
but how is a type checker to know that?
%
Indeed, both the venerable
\ocaml compiler as well as
recent techniques like
\sherrloc and \mycroft~\citep{Zhang2014-lv,Loncaric2016-uk,Pavlinovic2014-mr}.
fail to distinguish between
the two underlined expressions
in \autoref{fig:sumList};
it would be equally valid
to blame \emph{either}
of them alone.
%
The |[]| on line 3 could be changed to |0|,
or the |+| on line 4 could be changed to
either |@| (list append) or |::|, all of
which would give type-correct programs.
%
Thus, these state-of-the-art techniques
are forced to either blame \emph{both}
locations, or choose one \emph{arbitrarily}.

\mypara{Error Localization via Supervised Classification}
%
Our approach is to view error localization as a
\emph{supervised classification}
problem~\citep{Kotsiantis2007-pj}.
%
A \emph{classification} problem entails learning
a function that maps \emph{inputs} to a discrete
set of output \emph{labels} (in contrast to, say,
\emph{regression}, where the output is typically
a real number.)
%
A \emph{supervised} learning problem is one where
we are given a \emph{training set} where the
inputs and labels are known, and the task is to
learn a function that accurately maps the inputs
to output labels and \emph{generalizes} to new,
yet-unseen inputs.
%
To realize the above approach for error localization
as a practical tool, we have to solve four sub-problems.
%
\begin{enumerate}
  \item How can we acquire a \emph{training set} of
        blame-labeled ill-typed programs?

  \item How can we \emph{represent} blame-labeled programs
        as numeric vectors amenable to machine learning?

  \item How can we find \emph{features} that yield predictive
        models?

  \item How can we use the models to give localized
        \emph{feedback} to the programmer?
\end{enumerate}

\mysubsection{Step 1: Acquiring a Blame-Labeled Training Set}

The first step is to create a training
set of ill-typed programs, where each
erroneous sub-term is explicitly labeled.
%
Prior work has often enlisted
expert users to curate a set of
ill-typed programs and then
\emph{manually} determine the
correct fix~\citep[\eg][]{Lerner2007-dt,Loncaric2016-uk}.
%
This method is suitable for evaluating
the quality of a localization (or repair)
algorithm on a small number (\eg, 10-100s)
of programs.
%
However, in general it requires a great
deal of effort for the expert to divine
the original programmers' intentions.
%
Consequently, is difficult to scale the
expert-labeling to yield a dataset large
enough (\eg, 1000s of programs) needed to
facilitate machine learning.
%
More importantly, this approach fails to
capture the \emph{frequency} with which
errors occur in practice.

We solve both the scale and frequency problems
by instead extracting blame-labeled data sets
from \emph{interaction traces}.
%
Software development is an iterative process.
Programmers, perhaps after a lengthy (and
sometimes frustrating) back-and-forth with
the type checker, eventually end up fixing
their own programs.
%
Thus, we implemented an instrumented
version of the \ocaml compiler that records
this conversation, \ie records the sequence
of programs submitted by each programmer and
whether or not it was deemed type-correct.
%
For each ill-typed program in
a particular programmer's trace,
we find the \emph{first subsequent}
program in the trace that type checks
and declare it to be the fixed version.
%
From this pair of an ill-typed program
and its fix, we can extract a \emph{diff}
of the abstract syntax trees, and then assign
the blame labels to the \emph{smallest}
sub-tree in the diff.

For example, suppose our student
fixed the |sumList| program in
\autoref{fig:sumList} by replacing
|[]| with |0|, the diff would
include only the |[]| expression.
%
Thus we would determine that the
|[]| expression (and \emph{not} the
|+| or the recursive call |sumList t|)
is to blame.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\mysubsection{Step 2: Representing Programs as Vectors}

\mysubsection{Step 3: Feature Discovery}

\mysubsection{Step 4: Generating Feedback}

% Evaluation

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%






\paragraph{\textbf{Challenge (1): How to represent programs?}}

The first and prime challenge we address is how to translate programs
into a format favorable to learning a model of type errors.
%
Programs can be represented in various ways, from the raw text to
richly-structured abstract syntax trees and control-flow graphs, but
many representations are not directly amenable to machine learning.
%
Furthermore, program representations that are amenable to one learning
task, \eg code completion, may not be favorable to our problem of
assigning blame for type errors.

Machine learning techniques typically take as input \emph{feature
vectors}, fixed-length vectors of real numbers where each element
represents some property of the input.
%
Thus, to apply machine learning to our problem we must
determine:
%
(1) which features of a program would be useful for modeling type errors; and
%
(2) how can we represent a variable-size program as a fixed-length vector?

\paragraph{\textbf{Solution: Vectorized Abstract Syntax Trees}}
\ES{name up for grabs...}
We propose to extract features from the program's
abstract syntax tree (AST), a natural choice since the type checker
operates on ASTs.
%
We model features as \emph{queries} over the AST.\@
%
Our initial set of interesting features includes the syntactic class of
each expression.
%
That is, the classifier should be able to distinguish between the |[]|
and |+| expressions in \autoref{fig:sumList} because they represent
different syntactic expression forms.
%
Modeling the syntactic class of an expression gives the classifier a
basic notion of the relative frequency of blame assignment for the
various program elements, \ie perhaps |[]| is \emph{empirically} more
likely to be blamed than |+|.
% % ES: (2) doens't really make sense here
% (2) the type checker uses the syntactic class of an expression to
%     impose typing constraints on the neighboring expressions.

A programming language has a fixed set of AST elements,\footnote{We will
  discuss handling arbitrary, user-defined types in
  \autoref{sec:discussion}.} which suggests a natural way to obtain
fixed-size feature vectors. Rather than translating a program into a
single feature vector, we translate it into a \emph{set} of feature
vectors, one for each expression in the program.
%
Thus, the |[]| and |+| expressions will each be given their own feature
vector, and we will ask the classifier to predict for each
\emph{independently} whether it should be blamed.

Of course, each expression occurs in some \emph{context}, and we would
like the classifier to be able make decisions based on the context as
well.
%
The context is particularly important for our task as each expression
imposes typing constraints on its neighbors, \eg a |+| operator tells
the type checker that both children must have type |int| and that
the parent must accept an |int|.
%
We might expect that the recursive call |sumList t| is
unlikely to be at fault because |sumList| has a function type --- the
user may have called the wrong function or supplied the wrong argument,
but the application itself is probably correct.
%
Conversely, if the student wrote |h sumList t| (\ie forgot the |+|), we
might wish to blame the application rather than |h| because |h|
\emph{does not} have a function type.
%
Thus we extend each expression's feature vector with
\emph{contextual features} of its parent and children.

Our contextual features include the syntactic class of the neighboring
expressions, their inferred types (when available), and, crucially, whether
the expression occurs in a minimal type error \emph{slice}.
%
A minimal type error slice \citep{Haack2003-vc} includes all expressions that
are necessary for the error to manifest and no more.
%
We propose to use type error slices to communicate to the classifier
which expressions could potentially be blamed --- a change to an
expression outside of the minimal slice cannot possibly fix the type
error.
%
We will show that the type error slice is so important
(\autoref{sec:feature-utility}) that it is actually beneficial to
automatically discard expressions that are not part of the slice, rather
than letting the classifier learn to do so.
%
Our use of type error slices is conceptually related to the use of fault
localization in other program analysis and transformation techniques
(see \autoref{sec:related-work}).

\paragraph{\textbf{Challenge (2): What is the ``correct'' expression to blame?}}
%
%% As we saw in \autoref{fig:sumList},
%% type errors admit many different
%% fixes to different expressions,
%% each resulting in a different program.
%% %
%% How is the type checker to judge
%% which expressions are more likely
%% to be incorrect than others?

\paragraph{\textbf{Solution: Use the students' subsequent fixes}}
%
Rather than relying on expert users, we follow
\citet{Zhang2014-lv} \RJ{CHECK} and allow our students to
do the work of assigning blame themselves.
%
Software development is an iterative process and our students
eventually fix their own programs, perhaps after multiple ill-fated
attempts.



\paragraph{\textbf{Challenge (3): How can we intuitively present our feedback?}}
We now have the features and labels needed to train a classifier to
predict, for each expression in an ill-typed program, whether it should
be blamed.
%
But this is not yet particularly suitable as \emph{user feedback}.
%
A recent survey of developers by \citet{Kochhar2016-oc} found that
developers are unlikely to examine more than around five potentially
erroneous locations before falling back to manual debugging.
%
Thus, we should limit our predictions to a select few to be presented to
the user.

\paragraph{\textbf{Solution: Rank blame locations by ``confidence''}}
Luckily, many machine learning classifiers produce not only a predicted
label, but also a metric that can be interpreted as the classifier's
\emph{confidence} in its prediction.
%
Thus, we \emph{rank} each expression by the classifier's confidence that
it should be blamed, and present only the top-$k$ predictions to the
user (in practice $k=3$). This use of ranking to report
the results of a program analysis is popular in other problem domains
\citep[see, \eg][]{Kremenek2003-ck}; we focus
explicitly on the use of data-driven machine learning confidence as a
ranking source.



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
