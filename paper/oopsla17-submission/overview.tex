\section{Overview}
\label{sec:overview}

We start with an overview of our approach to localizing type errors by
learning a model of the mistakes programmers actually make.
%
We formulate the problem of type error localization as a
\emph{supervised classification} problem (see \citealt{Kotsiantis2007-pj}
for a survey).
%
A \emph{classification} problem entails learning a function that maps
inputs to a discrete set of output \emph{labels}, in contrast to
\emph{regression}, where the output is typically a real number.
%
In a \emph{supervised} learning problem one is given a \emph{training}
set where the inputs and labels are known, and the task is to learn a
function that accurately maps the inputs to outputs and
\emph{generalizes} to new, yet-unseen inputs.

The key technical challenges we address are:
%
(1) formulating type error localization as a classification problem;
%
%(2) generating correct labels for supervised learning; and
(2) identifying ``correct'' blame assignments in our dataset; and
%
(3) presenting the predictions of the classifier in an intuitive manner.

\paragraph{\textbf{Challenge (1): How to represent programs?}}
The first and prime challenge we address is how to translate programs
into a format favorable to learning a model of type errors.
%
Programs can be represented in various ways, from the raw text to
richly-structured abstract syntax trees and control-flow graphs, but
many representations are not directly amenable to machine learning.
%
Furthermore, program representations that are amenable to one learning
task, \eg code completion, may not be favorable to our problem of
assigning blame for type errors.

Machine learning techniques typically take as input \emph{feature
vectors}, fixed-length vectors of real numbers where each element
represents some property of the input.
%
Thus, to apply machine learning to our problem we must
determine:
%
(1) which features of a program would be useful for modeling type errors; and
%
(2) how can we represent a variable-size program as a fixed-length vector?

\paragraph{\textbf{Solution: Vectorized Abstract Syntax Trees}}
\ES{name up for grabs...}
We propose to extract features from the program's
abstract syntax tree (AST), a natural choice since the type checker
operates on ASTs.
%
We model features as \emph{queries} over the AST.\@
%
Our initial set of interesting features includes the syntactic class of
each expression.
%
That is, the classifier should be able to distinguish between the |[]|
and |+| expressions in \autoref{fig:sumList} because they represent
different syntactic expression forms.
%
Modeling the syntactic class of an expression gives the classifier a
basic notion of the relative frequency of blame assignment for the
various program elements, \ie perhaps |[]| is \emph{empirically} more
likely to be blamed than |+|.
% % ES: (2) doens't really make sense here
% (2) the type checker uses the syntactic class of an expression to
%     impose typing constraints on the neighboring expressions.

A programming language has a fixed set of AST elements,\footnote{We will
  discuss handling arbitrary, user-defined types in
  \autoref{sec:discussion}.} which suggests a natural way to obtain
fixed-size feature vectors. Rather than translating a program into a
single feature vector, we translate it into a \emph{set} of feature
vectors, one for each expression in the program.
%
Thus, the |[]| and |+| expressions will each be given their own feature
vector, and we will ask the classifier to predict for each
\emph{independently} whether it should be blamed.

Of course, each expression occurs in some \emph{context}, and we would
like the classifier to be able make decisions based on the context as
well.
%
The context is particularly important for our task as each expression
imposes typing constraints on its neighbors, \eg a |+| operator tells
the type checker that both children must have type |int| and that
the parent must accept an |int|.
%
We might expect that the recursive call |sumList t| is
unlikely to be at fault because |sumList| has a function type --- the
user may have called the wrong function or supplied the wrong argument,
but the application itself is probably correct.
%
Conversely, if the student wrote |h sumList t| (\ie forgot the |+|), we
might wish to blame the application rather than |h| because |h|
\emph{does not} have a function type.
%
Thus we extend each expression's feature vector with
\emph{contextual features} of its parent and children.

Our contextual features include the syntactic class of the neighboring
expressions, their inferred types (when available), and, crucially, whether
the expression occurs in a minimal type error \emph{slice}.
%
A minimal type error slice \citep{Haack2003-vc} includes all expressions that
are necessary for the error to manifest and no more.
%
We propose to use type error slices to communicate to the classifier
which expressions could potentially be blamed --- a change to an
expression outside of the minimal slice cannot possibly fix the type
error.
%
We will show that the type error slice is so important
(\autoref{sec:feature-utility}) that it is actually beneficial to
automatically discard expressions that are not part of the slice, rather
than letting the classifier learn to do so.
%
Our use of type error slices is conceptually related to the use of fault
localization in other program analysis and transformation techniques
(see \autoref{sec:related-work}).

\paragraph{\textbf{Challenge (2): What is the ``correct'' expression to blame?}}
As we saw in \autoref{fig:sumList}, type errors admit many different
fixes to different expressions, each resulting in a different program.
%
How is the type checker to judge which expressions are more likely to be
incorrect than others?
%
Prior work has often enlisted expert users to manually judge ill-typed
programs and determine the ``correct'' fix
\citep[\eg][]{Loncaric2016-uk}, but this approach does not scale well to
a dataset large enough to support machine learning.
%
Furthermore, while expert users have intimate knowledge of the type system,
they cannot know in general what novice users \emph{intended} to do.

\paragraph{\textbf{Solution: Use the students' subsequent fixes}}
%
Rather than relying on expert users, we allow our
students to do the work of assigning blame themselves.
%
Software development is an iterative process and our students
eventually fix their own programs, perhaps after multiple ill-fated
attempts.
%
For each ill-typed program in our dataset, we find the first
\emph{subsequent} program that type checks and declare that to be the
fix.
%
From this pair of an ill-typed program and its fix, we can extract a
\emph{diff} of the abstract syntax trees.
%
For example, suppose our student fixed the |sumList| program in
\autoref{fig:sumList} by replacing |[]| with |0|, the diff would include
only the |[]| expression.
%
Thus we would determine that the |[]| expression (and \emph{not} the
|+| or the recursive call |sumList t|) is to blame.


\paragraph{\textbf{Challenge (3): How can we intuitively present our feedback?}}
We now have the features and labels needed to train a classifier to
predict, for each expression in an ill-typed program, whether it should
be blamed.
%
But this is not yet particularly suitable as \emph{user feedback}.
%
A recent survey of developers by \citet{Kochhar2016-oc} found that
developers are unlikely to examine more than around five potentially
erroneous locations before falling back to manual debugging.
%
Thus, we should limit our predictions to a select few to be presented to
the user.

\paragraph{\textbf{Solution: Rank blame locations by ``confidence''}}
Luckily, many machine learning classifiers produce not only a predicted
label, but also a metric that can be interpreted as the classifier's
\emph{confidence} in its prediction.
%
Thus, we \emph{rank} each expression by the classifier's confidence that
it should be blamed, and present only the top-$k$ predictions to the
user (in practice $k=3$). This use of ranking to report
the results of a program analysis is popular in other problem domains
\citep[see, \eg][]{Kremenek2003-ck}; we focus
explicitly on the use of data-driven machine learning confidence as a
ranking source.



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
