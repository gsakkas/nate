\section{Evaluation}
\label{sec:evaluation}
\input{data}

We have implemented our technique for localizing type errors for a
purely functional subset of \ocaml with polymorphic types and functions.
%
We seek to answer three questions in our evaluation:
%
\begin{description}
\item[1. Blame Accuracy (\autoref{sec:quantitative})]
  %
  How often are our predictions \emph{correct}?
  % For how many ill-typed programs can we accurately predict the source
  % of the error?
\item[2. Feature Utility (\autoref{sec:feature-utility})]
  %
  Which feature sets are \emph{most important} in general?
  % How much do the features described in \autoref{sec:features}
  % contribute to our predictions?
\item[3. Explaining Predictions (\autoref{sec:qualitative})]
  %
  Can we \emph{explain} individual predictions (correct or not)?
\end{description}
\ES{may want to swap (1) and (2)..}

\subsection{Methodology}
\label{sec:methodology}

We answer our questions on two sets of data gathered from the
undergraduate Programming Languages course at
\begin{anonsuppress}
UC San Diego (IRB \#140608).
\end{anonsuppress}
\begin{noanonsuppress}
AUTHOR's INSTITUTION.
\end{noanonsuppress}
%
We recorded each interaction with the \ocaml top-level system over the
course of the first three assignments, capturing
ill-typed programs and, crucially, their subsequent fixes.
%
The first dataset comes from the Spring 2014 class (\SPRING), with a
cohort of 46 students. The second comes from the Fall 2015 class
(\FALL), with a cohort of 56 students.
%
The extracted programs are relatively small, but they demonstrate a
range of functional programming idioms, \eg higher-order functions and
(polymorphic) algebraic data types.

\paragraph{Feature Selection}
We extract a set of 276 features from each sub-expression in a student
program, including:
%
\begin{enumerate}
\item 44 local syntactic features. In addition to the syntax of \lang,
  we support the full range of arithmetic operators (integer and
  floating point), equality and comparison operators, character and
  string literals, and a user-defined |expr| type of simple arithmetic
  expressions. We discuss the challenge of supporting other
  user-defined types in \autoref{sec:discussion}.
\item 176 contextual syntactic features. For each sub-expression we
  additionally extract the local syntactic features of its parent and
  first, second, and third (left-to-right) children. If an expression
  does not have a parent or children, these features will simply be
  disabled. If an expression has more than three children, the
  classifiers will receive no information about the additional
  children.
\item 55 typing features. In addition to the types of \lang, we support
  |int|s, |float|s, |char|s, |string|s, and the user-defined |expr|
  mentioned above. These features are extracted for each sub-expression
  and for the contextual sub-expressions.
\item one feature denoting the size of each sub-expression.
% \item one feature denoting whether each sub-expression is part of the
%   minimal type error slice.
\end{enumerate}

\paragraph{Blame Oracle}
We identified the fixes for each ill-typed program with an
expression-level diff~\citep{Lempsink2009-xf}.
%
We consider two sources of changes:
%
\begin{enumerate}
\item If an expression has been removed wholesale, \eg if $\eapp{f}{x}$
  is rewritten to $\eapp{g}{x}$, we will mark the expression $f$ as
  changed, as it has been replaced by $g$.
\item If a new expression has been inserted \emph{around} an existing
  expression, \eg if $\eapp{f}{x}$ is rewritten to
  $\eplus{\eapp{f}{x}}{1}$, we will mark the application expression
  $\eapp{f}{x}$ (but not $f$ or $x$) as changed, as the $+$ operator now
  occupies the original location of the application.
\end{enumerate}

Students may have made many, potentially unrelated, changes between
compilations, but at some point the ``fix'' becomes a ``rewrite''.
%
We do not wish to consider the ``rewrites'' in our evaluation, so we
discard outliers where the fraction of expressions that have changed is
more than one standard deviation above the mean, or 44\%.
%
This accounts for roughly 14\% of each dataset, leaving us with
2,425 program pairs for \SPRING and 2,325 pairs for \FALL.

% we discard any program pairs where more than 40\%
% of the sub-expressions have changed.
% %
% We picked 40\% as an estimate of the inflection point where we could
% still retain the large majority of program pairs.
% % FIXME: Can you say that this dataset curation is similar to any other
% % datasets (e.g., the washington one)? Anything you could cite and discuss
% % here would take some of the pressure off.


\paragraph{Accuracy Metric}
All of the tools we compare (with the exception of the standard \ocaml
compiler) can produce a list of potential error locations. 
%
However, in a study of fault localization techniques,
\citet{Kochhar2016-oc} show that most developers will not consider more
than around five potential error locations before falling back to manual
debugging.
%
Type errors are relatively simple in comparison to general fault
localization, thus we limit our evaluation to the top three predictions
of each tool.
%
We evaluate each tool on whether a changed expression occurred in its
top one, top two, or top three predictions.

\input{evaluation-accuracy}
\input{evaluation-utility}
\input{gallery}

\subsection{Threats to Validity} 

Although our experiments demonstrate that our technique can pinpoint type
errors more accurately than the state of the art and that our features are
relevant to blame assignment, our results may not generalize. 

One threat to validity associated with supervised machine learning is
overfitting (\ie learning a model that is too complex with respect to the
data). We mitigate this threat by having separate training and testing
datasets (section FIXME) and via cross-validation (section
FIXME)~\cite{FIXME}. 

FIXME threat associated with benchmarks that are not indicative. We
mitigate this threat by including the largest empirical evaluation we are
aware of (re-quote number of program pairs) from two different semesters of
students (re-quote number of students). FIXME note that we ack that
students are not indicative of industrial programmers, but the goal of this
paper is to help novices, since they find type inference errors to be the
most cryptic~\cite{FIXME}. 

FIXME threat associated with removing from the dataset program pairs
that change everything or where our parser cannot find nodes corresponding
to the other tools or whatever. FIXME Note that the former is
standard or otherwise similar to previous work~\cite{FIXME}. FIXME note tha
the latter actually helps the state of the art, and anyway our victory
margins are so large that even if assumed they were perfect on all of those
and we were not, we'd still win (double check that math). 

FIXME threat associated with using just OCaml instead of Haskell, Reason,
whatever. FIXME admits comparison with previous work, FIXME our functional
subset of ocaml is basically haskell anyway, FIXME Algorithm W is the same
for all of them.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
