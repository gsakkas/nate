\section{Evaluation}
\label{sec:evaluation}
\input{data}

We have implemented our technique for localizing type errors for a
purely functional subset of \ocaml with polymorphic types and functions.
%
We seek to answer three questions in our evaluation:
%
\begin{description}
\item[1. Blame Accuracy (\autoref{sec:quantitative})]
  %
  How often are our predictions \emph{correct}?
  % For how many ill-typed programs can we accurately predict the source
  % of the error?
\item[2. Feature Utility (\autoref{sec:feature-utility})]
  %
  Which feature sets are most important in general?
  % How much do the features described in \autoref{sec:features}
  % contribute to our predictions?
\item[3. Explaining Predictions (\autoref{sec:qualitative})]
  %
  Can we explain \emph{individual} predictions (correct or not)?
\end{description}
\ES{may want to swap (1) and (2)..}

\subsection{Methodology}
\label{sec:methodology}

We answer our questions on two sets of data gathered from the
undergraduate Programming Languages course at
\if@anonymous
AUTHOR INSTITUTION.
\else
UC San Diego (IRB \#140608).
\fi
%
We recorded each interaction with the \ocaml top-level system over the
course of the first three assignments, which allowed us to capture
ill-typed programs and, crucially, their subsequent fixes.
%
The first dataset comes from the Spring 2014 class (\SPRING), from which
we extracted 2,333 pairs of programs, and the second comes from the Fall
2015 class (\FALL), from which we extracted 2,273 pairs of programs.
%
The extracted programs are relatively small, but they demonstrate a
range of functional programming idioms, \eg higher-order functions and
(polymorphic) algebraic data types.

We identified the fixes for each ill-typed program with an
expression-level diff~\citep{Lempsink2009-xf}.
%
We consider two sources of changes:
%
\begin{enumerate}
\item If an expression has been removed wholesale, \eg if $\eapp{f}{x}$
  is rewritten to $\eapp{g}{x}$, we will mark the expression $f$ as
  changed, as it has been replaced by $g$.
\item If a new expression has been inserted \emph{around} an existing
  expression, \eg if $\eapp{f}{x}$ is rewritten to
  $\eplus{\eapp{f}{x}}{1}$, we will mark the application expression
  $\eapp{f}{x}$ (but not $f$ or $x$) as changed, as the $+$ operator now
  occupies the original location of the application.
\end{enumerate}
%
As the students may have made many, potentially unrelated, changes
between compilations, we discard any program pairs where more than 40\%
of the sub-expressions have changed.
%
We picked 40\% as an estimate of the inflection point where we could
still retain the large majority of program pairs.


\paragraph{Accuracy Metric}
All of the tools we compare (with the exception of \ocaml) can produce a
list of potential error locations, which might in the limit include the
entire type error slice.
%
However, in a study of fault localization techniques,
\citet{Kochhar2016-oc} show that most developers will not consider more
than around five potential error locations before falling back to manual
debugging.
%
Type errors are relatively simple in comparison to general fault
localization, thus we limit our evaluation to the top three predictions
of each tool.
%
We evaluate each tool on whether a changed expression occurred in its
top 1, top 2, or top 3 predictions.

\input{evaluation-accuracy}
\input{evaluation-utility}

\input{gallery}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
