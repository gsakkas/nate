\section{Evaluation}
\label{sec:evaluation}
\input{data}

We have implemented our technique for localizing type errors for a
purely functional subset of \ocaml with polymorphic types and functions.
%
We seek to answer three questions in our evaluation:
%
\begin{description}
\item[1. Blame Accuracy (\autoref{sec:quantitative})]
  %
  How often are our predictions \emph{correct}?
  % For how many ill-typed programs can we accurately predict the source
  % of the error?
\item[2. Feature Utility (\autoref{sec:feature-utility})]
  %
  Which feature sets are \emph{most important} in general?
  % How much do the features described in \autoref{sec:features}
  % contribute to our predictions?
\item[3. Explaining Predictions (\autoref{sec:qualitative})]
  %
  Can we \emph{explain} individual predictions (correct or not)?
\end{description}
\ES{may want to swap (1) and (2)..}

\subsection{Methodology}
\label{sec:methodology}

We answer our questions on two sets of data gathered from the
undergraduate Programming Languages course at
\begin{anonsuppress}
UC San Diego (IRB \#140608).
\end{anonsuppress}
\begin{noanonsuppress}
AUTHOR's INSTITUTION.
\end{noanonsuppress}
%
We recorded each interaction with the \ocaml top-level system over the
course of the first three assignments, capturing
ill-typed programs and, crucially, their subsequent fixes.
%
The first dataset comes from the Spring 2014 class (\SPRING), with a
cohort of 46 students. The second comes from the Fall 2015 class
(\FALL), with a cohort of 56 students.
%
The extracted programs are relatively small, but they demonstrate a
range of functional programming idioms, \eg higher-order functions and
(polymorphic) algebraic data types.

\paragraph{Feature Selection}
We extract a set of 276 features from each sub-expression in a student
program, including:
%
\begin{enumerate}
\item 44 local syntactic features. In addition to the syntax of \lang,
  we support the full range of arithmetic operators (integer and
  floating point), equality and comparison operators, character and
  string literals, and a user-defined |expr| type of simple arithmetic
  expressions. We discuss the challenge of supporting other
  user-defined types in \autoref{sec:discussion}.
\item 176 contextual syntactic features. For each sub-expression we
  additionally extract the local syntactic features of its parent and
  first, second, and third (left-to-right) children. If an expression
  does not have a parent or children, these features will simply be
  disabled. If an expression has more than three children, the
  classifiers will receive no information about the additional
  children.
\item 55 typing features. In addition to the types of \lang, we support
  |int|s, |float|s, |char|s, |string|s, and the user-defined |expr|
  mentioned above. These features are extracted for each sub-expression
  and for the contextual sub-expressions.
\item one feature denoting the size of each sub-expression.
% \item one feature denoting whether each sub-expression is part of the
%   minimal type error slice.
\end{enumerate}

\paragraph{Blame Oracle}
We identified the fixes for each ill-typed program with an
expression-level diff~\citep{Lempsink2009-xf}.
%
We consider two sources of changes:
%
\begin{enumerate}
\item If an expression has been removed wholesale, \eg if $\eapp{f}{x}$
  is rewritten to $\eapp{g}{x}$, we will mark the expression $f$ as
  changed, as it has been replaced by $g$.
\item If a new expression has been inserted \emph{around} an existing
  expression, \eg if $\eapp{f}{x}$ is rewritten to
  $\eplus{\eapp{f}{x}}{1}$, we will mark the application expression
  $\eapp{f}{x}$ (but not $f$ or $x$) as changed, as the $+$ operator now
  occupies the original location of the application.
\end{enumerate}

Students may have made many, potentially unrelated, changes between
compilations, but at some point the ``fix'' becomes a ``rewrite''.
%
We do not wish to consider the ``rewrites'' in our evaluation, so we
discard outliers where the fraction of expressions that have changed is
more than one standard deviation above the mean, or 44\%.
%
This accounts for roughly 14\% of each dataset, leaving us with
2,425 program pairs for \SPRING and 2,325 pairs for \FALL.

% we discard any program pairs where more than 40\%
% of the sub-expressions have changed.
% %
% We picked 40\% as an estimate of the inflection point where we could
% still retain the large majority of program pairs.
% % FIXME: Can you say that this dataset curation is similar to any other
% % datasets (e.g., the washington one)? Anything you could cite and discuss
% % here would take some of the pressure off.


\paragraph{Accuracy Metric}
All of the tools we compare (with the exception of the standard \ocaml
compiler) can produce a list of potential error locations. 
%
However, in a study of fault localization techniques,
\citet{Kochhar2016-oc} show that most developers will not consider more
than around five potential error locations before falling back to manual
debugging.
%
Type errors are relatively simple in comparison to general fault
localization, thus we limit our evaluation to the top three predictions
of each tool.
%
We evaluate each tool on whether a changed expression occurred in its
top one, top two, or top three predictions.

\input{evaluation-accuracy}
\input{evaluation-utility}
\input{gallery}

\subsection{Threats to Validity} 

Although our experiments demonstrate that our technique can pinpoint type
errors more accurately than the state of the art and that our features are
relevant to blame assignment, our results may not generalize. 

One threat to validity associated with supervised machine learning is
overfitting (\ie learning a model that is too complex with respect to
the data).
%
We mitigate this threat by having separate training and testing datasets
(\autoref{sec:quantitative}) and via cross-validation
(\autoref{sec:feature-utility})~\cite{FIXME}.

Our benchmarks were drawn from students in an undergraduate course and
may not be representative of other student populations.
%
We mitigate this threat by including the largest empirical evaluation of
type error localization that we are aware of: over 4,500 pairs of
ill-typed programs and fixes from two instances of the course, with
programs from 102\ES{TODO: check} different students.
%
We acknowledge, of course, that students are not industrial programmers
and our results may not translate to large-scale software development;
however, we are particularly interested in aiding novice programmers
as they learn to work inside the type system.

Our removal of program pairs that changed too much, where our oracle
could not identify the blame of the other tools, or where the other
tools timed out or encountered unsupported language features is another
threat to validity.
%
It is possible that including the programs that changed excessively
would hurt our models, or that the other tools would perform
better on the programs with unsupported language features.
%
We note however that
%
(1) outlier removal is a standard technique in machine learning
\ES{CITE?}; and
%
(2) our Top-1 accuracy margin is large enough that even if we assumed
that \sherrloc were perfect on all of the excluded programs, it would
only tie our \hiddenFH in Top-1 accuracy.
%
\ES{I think this is accurate, but should double check..}

Examining programs written in \ocaml as opposed to \haskell or any other
language poses another threat to validity, common type errors may differ
in different languages.
%
\ocaml is, however, a standard target for research in type error
localization and thus our choice admits a direct comparison with prior
work.
%
Furthermore, the functional core of \ocaml that we support does not
differ significantly from the functional core of \haskell or SML, all of
which are effectively lambda calculi with a Hindley-Milner-style type
system.\footnote{\haskell's type classes are a notable exception, they
  are also known to cause confusing type errors and would be interesting
  to study in future work.}

Finally, our use of student fixes as oracles for the source of type
errors assumes that, on average, students are able to correctly identify
the source of an error.
%
As the students are in the process of learning the language and type
system, this assumption may be faulty.
%
It may be that \emph{expert} users would disagree with many of the
student fixes, and that it is harder to learn a model of expert fixes,
or that the state of the art would be better at predicting expert fixes.
%
As we have noted before, we believe it is reasonable to use student
fixes as oracles because the student is the best judge of what she
\emph{meant} to do.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
