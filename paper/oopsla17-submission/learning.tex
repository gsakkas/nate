\section{Learning to Blame}
\label{sec:learning}
In this section, we describe our approach to localizing type errors, in the
context
of \lang (\autoref{fig:syntax}), a simple lambda calculus with integers,
booleans, pairs, and lists.
%
Our goal is to instantiate the $\blamesym$ function of
\autoref{fig:api}, which takes as input a $\Model$ of type errors and an
ill-typed program $e$, and returns an ordered list of subexpressions
from $e$ paired with the probability $\Runit$ that they should be
blamed.

A $\Model$ is produced by the $\trainsym$ function, which performs
supervised learning on a training set of feature vectors $\V$ and
(boolean) labels $\B$.
%
Once trained, a $\Model$ can be $\evalsym$uated on a new input vector,
producing the probability $\Runit$ that the blame label should be
applied.
%
We describe multiple types of $\Model$ and their instantiations of
$\trainsym$ and $\evalsym$ in \autoref{sec:models}.

Of course, the $\Model$ expects feature vectors $\V$ and blame labels
$\B$, but we are given program pairs.
%
So our first step must be to define a suitable translation from program
pairs to feature vectors and labels, \ie we must define the
$\extractsym$ function in \autoref{fig:api}.
%
We accomplish this by modeling features as real-valued functions of
expressions, and extract a feature vector for each \emph{subexpression}
of the ill-typed program (\autoref{sec:features}).
%
Then we define the blame labels for the training set to be the
subexpressions that changed between the ill-typed program and its
subsequent fix, and model $\blamesym$ as a function from a program pair
to the set of expressions that changed (\autoref{sec:labels}).
%
The $\extractsym$ function, then, extracts $\featuresym$ from each
subexpression and computes the blamed expressions according to
$\labelsym$.

% First, we define the inputs to the model, a set of \emph{features}
% (\autoref{sec:features}) that we will use to describe programs.
% %
% Second, we define the expected outputs of the model, a set of
% \emph{labels} (\autoref{sec:labels}) that we will use to assign blame.
% %
% Third, we describe the actual \emph{models} (\autoref{sec:models}) that we
% will evaluate.

\input{syntax}

\subsection{Features}
\label{sec:features}

% \begin{figure}[ht]
% \begin{minipage}{0.6\linewidth}
% \begin{code}
%   let rec sumList xs =
%     match xs with
%     | []     -> []
%     | hd::tl -> hd + sumList tl
% \end{code}
% \end{minipage}
% \begin{minipage}{0.3\linewidth}
% \begin{code}[numbers=left]
% []
% hd + sumList tl
% sumList tl
% tl
% \end{code}
% \end{minipage}
% \caption{An ill-typed program (left) and a selection of its
%   sub-expressions (right).}
% \label{fig:sumList}
% \end{figure}
\begin{table}[ht]
\caption{Example Feature Vectors}\label{tab:sumList}
\begin{tabular}{lrrrrrr}
\toprule
Expression
  & \IsNil & \IsCaseListP & \ExprSize
  & \HasTypeIntCOne & \HasTypeList & \InSlice \\
\midrule
|[]|
  & 1 & 1 & 1 & 0 & 1 & 1 \\
|hd + sumList tl|
  & 0 & 1 & 5 & 1 & 0 & 1 \\
|sumList tl|
  & 0 & 0 & 3 & 0 & 1 & 1 \\
|tl|
  & 0 & 0 & 1 & 0 & 1 & 0 \\
\bottomrule
\end{tabular}
\bigskip
\caption*{A selection of the features we would extract from the
\lstinline!sumList! program in \autoref{fig:sumList}. A feature is
considered \emph{enabled} if it has a non-zero value, and
\emph{disabled} otherwise. A ``-P'' suffix indicates that the feature
describes the parent of the current expression, a ``-C$n$'' suffix
indicates that the feature describes the $n$-th (left-to-right) child of
the current expression.  Note that, since we rely on a partial typing
derivation, we are subject to the well-known traversal bias and label
the expression \lstinline!sumList tl! as having type
$\tlist{\cdot}$. The model will have to learn to correct for this bias.}
\end{table}
The first issue we must tackle is formulating our learning task in
machine learning terms.
%
We are given programs over \lang, but the learning algorithms expect to work
with \emph{feature vectors} $\V$ --- vectors of real numbers, where each
column describes a particular aspect of the input.
%
Thus, our first task is to convert programs to feature vectors.

We choose to model a program as a \emph{set} of feature vectors, where
each element corresponds an expression in the program.
%
Thus, given the |sumList| program in \autoref{fig:sumList} we
would first split it into its constituent sub-expressions and then
transform each sub-expression into a single feature vector.
%
We group the features into five categories, using \autoref{tab:sumList}
as a running example of the feature extraction process.

\subsubsection{Local syntactic features}
These features describe the syntactic category of each expression $e$.
%
In other words, for each production of $e$ in \autoref{fig:syntax} we
introduce a feature that is enabled (set to $1$) if the expression was
built with that production, and disabled (set to $0$) otherwise.
%
For example, the \IsNil feature in \autoref{tab:sumList} describes
whether an expression is the empty list $\enil$.

We distinguish between matching on a list vs.\ on a pair, as this
affects the typing derivation.
%
We also assume that all pattern matches are well-formed --- \ie all
patterns must match on the same type.
%
Ill-formed match expressions would lead to a type error; however, they
are already effectively localized to the match expression itself.
%
We note that this is not a \emph{fundamental} limitation, and one could
easily add features that specify whether a match \emph{contains} a
particular pattern, and thus have a match expression that enables multiple
features.

\subsubsection{Contextual syntactic features}
These are similar to local syntactic features, but lifted to describe the
parent and children of an expression.
%
For example, the \IsCaseListP feature in \autoref{tab:sumList} describes
whether an expression's \emph{parent} matches on a list.
%
If a particular $e$ does not have children (\eg a variable $x$) or a
parent (\ie the root expression), we leave the corresponding features
disabled.
%
This gives us a notion of the \emph{context} in which an expression
occurs, similar to the \emph{n-grams} commonly used in linguistic
models \citep{Hindle2012-hf,Gabel2010-el}.

% Instead of just describing the immediate context, we could describe
% whether a particular syntax element occurs in the neighboring
% expressions (or even a count of how many times it occurs).
% %
% For example, the \CountVarP feature in \autoref{tab:sumList} describes
% how many variables are contained in the expression \emph{rooted} at the
% current expression's parent.
% %
% Such fuzzier notions of context may enable increased precision in the
% model, but they also introduce opportunities for \emph{overfitting} ---
% where the model memorizes particular inputs rather than learning general
% patterns.
% %
% We will investigate (\ES{maybe..}) the impact of these alternatives
% in \autoref{sec:evaluation}.

\subsubsection{Expression size}
We also propose a feature representing the \emph{size} of each expression,
\ie how many sub-expressions does it contain?
%
For example, the \ExprSize feature in \autoref{tab:sumList} is set to three
for the expression |sumList tl| as it contains three expressions:
the two variables and the application itself.
%
This allows the model to learn that, \eg, expressions closer to the
leaves are more likely to be blamed than expressions closer to the root.

\subsubsection{Typing features}
A natural way of summarizing the context in which an expression occurs
is with \emph{types}.
%
Of course, the programs we are given are \emph{untypeable}, but we can
still extract a \emph{partial} typing derivation from the type checker
and use it to provide more information to the model.

A difficulty that arises here is that, due to the parametric type
constructors $\tfun{\cdot}{\cdot}$, $\tprod{\cdot}{\cdot}$, and
$\tlist{\cdot}$, there is an \emph{infinite} set of possible types ---
but we must have a \emph{finite} set of features.
%
Thus, we abstract the type of an expression to the set of type
constructors it \emph{mentions}, and add features for each type
constructor that describe whether a given type mentions the type
constructor.
%
For example, the type $\tint$ would only enable the $\tint$ feature,
while the type $\tfun{\tint}{\tbool}$ would enable the
$\tfun{\cdot}{\cdot}$, $\tint$, and $\tbool$ features.

We add these features for parent and child expressions to summarize the
context, but also for the current expression, as the type of an
expression is not always clear \emph{syntactically}.
%
For example, the expressions |tl| and |sumList tl|
in \autoref{tab:sumList} both enable the feature \HasTypeList, as they
are both inferred to have a type that mentions the $\tlist{\cdot}$
constructor.

Note that our use of typing features in an ill-typed program subjects us
to \emph{traversal bias} \citep{McAdam1998-ub}. For example, the
|sumList tl| expression might alternatively be assigned the type
$\tint$.
%
Our models will have to learn good localizations in spite this bias (see
\autoref{sec:evaluation}).

\subsubsection{Type error slice}
Finally, we wish to distinguish between changes that could fix the
error, and changes that \emph{cannot possibly} fix the error.
%
Thus, we compute a minimal type error \emph{slice} for the program
(\ie the set of expressions that contribute to the error), and add a
feature that is enabled for expressions that are part of the slice.
%
The \InSlice feature in \autoref{tab:sumList} indicates whether an
expression is part of such a minimal slice, and is enabled for all of
the sampled expressions except for |tl|, which does not affect
the type error.
%
If the program contains multiple type errors, we compute
a minimal slice for each error.

In practice, we have found that \InSlice is a particularly important
feature, and thus include a post-processing step that discards all
expressions where it is disabled.
%
As a result, the |tl| expression would never actually be shown to the
classifier.
%
 We will demonstrate the importance of \InSlice empirically in
\autoref{sec:feature-utility}.

\subsection{Labels}
\label{sec:labels}
We define the output of the model to be a boolean label, where ``false''
means the expression \emph{should not} change and ``true'' means the
expression \emph{should} change.
%
This allows us to predict whether any individual expression should
change, but we would actually like to predict the \emph{most likely}
expressions to change.
%
Many learning algorithms produce not only a prediction, but also a
metric that can be interpreted as a \emph{confidence} in the prediction.
%
Thus, we \emph{rank} the expressions by the model's confidence that they
will change, and select only the top $k$ (in practice $k=3$) to present
to the user.

We identify the fixes for each ill-typed program with an
expression-level diff~\citep{Lempsink2009-xf}.
%
We consider two sources of changes:
%
\begin{enumerate}
\item If an expression has been removed wholesale, \eg if $\eapp{f}{x}$
  is rewritten to $\eapp{g}{x}$, we will mark the expression $f$ as
  changed, as it has been replaced by $g$.
\item If a new expression has been inserted \emph{around} an existing
  expression, \eg if $\eapp{f}{x}$ is rewritten to
  $\eplus{\eapp{f}{x}}{1}$, we will mark the application expression
  $\eapp{f}{x}$ (but not $f$ or $x$) as changed, as the $+$ operator now
  occupies the original location of the application.
\end{enumerate}

\subsection{Learning Algorithms}
\label{sec:models}
\lstDeleteShortInline{|} % sigh...

Recall that we formulate type error localization as a supervised
classification problem.
%
This means that we assume the existence of a training set
$S = \{\langle \mathbf{x}_i, y_i \rangle\}_{i=1}^{n}$
of sample inputs $\mathbf{x}$ and their corresponding labels $y$.
%
The learning task is to model the probability $Pr(y\ |\ \mathbf{x})$
of a label being assigned to a given input.

There are many learning algorithms to choose from, existing
on a spectrum that balances expressiveness with ease of training (and of
interpreting the learned model).
%
In this section we consider four standard learning algorithms: 
%
(1) logistic regression,
(2) decision trees,
(3) random forests, and
(4) neural networks.
%
A thorough introduction to these techniques can be found in introductory
machine learning textbooks (\eg \ES{TODO: huma/kamalika?}).
%
We will briefly introduce each technique by describing the model it
learns, the training procedure, any hyper-parameters that must be tuned
by a human, and a summary of its advantages and disadvantages.

FIXME: Wes thinks the entire rest of this section, up to ``4. Evaluation'', 
contains much more detail than an OOPSLA audience wants on
introductory/undergraduate machine learning. (Especially since nothing
after this point is a novel contribution we make.) Perhaps we can cut some
space by focusing on the pros and cons of each technique rather than
describing the details? This is a PL paper. 

\paragraph{Logistic Regression}
% The simplest model we investigate is logistic regression, which learns a
% linear function of the features.
% %
% The goal is to learn a set of weights $W$ and biases $b$ such that the
% function
% %
% $$
% Pr(y\ |\ \mathbf{x}) = \frac{1}{1 + \mathsf{exp}(-W\mathbf{x} - b)}
% $$
% %
% effectively maps feature vectors $\mathbf{x}$ to labels $y$.

% \ES{TODO: talk about logistic regression and the loss function?}

The simplest model we investigate is logistic regression, which can be
understood in two steps.
%
First, we compute the \emph{evidence} for a label $y$ as a linear
function of the feature vector $\mathbf{x}$, using a weight vector
$\mathbf{w}$ and a bias $b$ that will be learned from the training set.
$$
\mathsf{ev} = \sum_j w_j x_j + b
$$
Then we use the logistic function (also called a sigmoid function)
$\sigma(x) = 1 / (1 + e^{-x})$ to compress the evidence term into the
$[0,1]$ interval, which can then be interpreted as the probability that
the label $y$ should be applied.
%
This gives us the final model:
$$
Pr(y\ |\ \mathbf{x}) = \frac{1}{1 + \mathsf{exp}(-\sum_j w_j x_j - b)}
$$
% $$
% Pr(y\ |\ \mathbf{x}) = \frac{1}{1 + e^{-\mathsf{ev}}}
% $$

Training a logistic regression entails finding optimal values for the
weights and bias, such that a \emph{cost} function is minimized.
%
In practice, the cost function used for logistic regression is the
\emph{cross entropy}, a measure of the similarity between two
probability distributions, between the predicted labels and the ground
truth.
%
The search for optimal values is typically done via \emph{stochastic
  gradient descent}, an iterative method for optimizing a cost function.
%
Starting with an initial estimate of the weights (\eg a normal
distribution), one repeatedly makes predictions for the training data,
computes the cost function for the predictions, and updates the
parameters according to the gradient of the cost function.
%
This process is repeated until the parameters converge, or until a time
limit is exhausted.
%
Stochastic gradient descent requires a hyper-parameter $\eta$, often
called the \emph{learning rate}, which controls how much the weights and
bias are updated at each iteration.

It has been observed that large weights often coincide with
\emph{overfitting} of the model --- where the model performs well on the
training samples but not on the testing samples.
%
Thus, it is common to add a \emph{regularization} term to the cost
function, a popular choice is the $L_2$ norm of the weights
$\sum_j w_j^2$, which has the effect of penalizing the model for
learning large weights \citep{Park2008-no}.
%
The contribution of the regularization term to the overall cost function
is controlled by another hyper-parameter $\lambda$, often called the
regularization rate.

As a generalized linear model, logistic regression is popular for its
ease of training and of interpreting the resulting model; however, it
can be limited in its applicability.
%
In particular, it may perform poorly when asked to learn an inherently
\emph{nonlinear} function.
%
This limitation can be mitigated by adding transformed or compound
features to the model --- \eg if one knows that the label has a
quadratic relationship with a feature $x$, the transformed feature $x^2$
can be added --- but this typically requires knowledge of the underlying
model.

% This limitation can be mitigated to some extent by adding more features
% to the model (\eg combinations of the existing features \ES{CITE?}), but
% the fundamental issue remains.

\paragraph{Decision Trees}
Decision tree algorithms learn a tree of binary predicates over the
features, recursively partitioning the input space until a final
classification can be made.
%
Each node in the tree contains a single predicate of the form
$x_j \leq t$ for some feature $x_j$ and threshold $t$, which determines
whether a given input should proceed down the left or right subtree.
%
Each leaf is labeled with a prediction and the fraction of training
samples that would reach it, the latter quantity can be interpreted as
the decision tree's confidence in its prediction.
\ES{HUMA: is this correct?}

Training a decision tree entails finding both a set of good partitioning
predicates and a good ordering of the predicates.
%
This is usually done in a top-down greedy manner by selecting the
predicate the best partitions the entire training set, and recursively
partitioning the subsets.
%
Standard algorithms for training decision trees include C4.5
\citep{Quinlan1993-de} and CART \citep{Breiman1984-qy}.
%
Overfitting can also be a problem for decision trees; the countermeasure
is usually either halting the learning process before the tree grows too
deep, or pruning the resulting tree.

The advantages of decision trees are that they are relatively easy to
train and that they produce a \emph{white-box} model, making it trivial
to analyze the entire model and explain individual predictions.
%
The disadvantages are that they are prone to overfitting and that the
model can be unstable, \ie small changes to the training data may
produce large changes in the model.
%
Both disadvantages are addressed by random forests.

\paragraph{Random Forests}
One technique for increasing the accuracy of a classifier is to train an
\emph{ensemble} of distinct classifiers and use a majority vote
to make the final prediction.
%
Random forests are an instance of this method, with decision
trees as the underlying classifiers.
%
The training process involves taking $N$ random subsets of the training
data and training a separate decision tree on each subset --- the
training process for the decision trees is often modified slightly to
reduce correlation between trees, by forcing the tree to pick features
from a random subset of all features at each node.
%
In order to make a prediction for an unseen sample, the random forest
asks each decision tree to make a prediction, and then predicts the most
common label.

The diversity of the underlying models tends to make random forests less
susceptible to the overfitting and instability of decision trees, but it
also makes the learned model more difficult to interpret.
%
Furthermore, the number of trees in the forest, $N$, becomes an important
hyper-parameter that must be set manually.


\paragraph{Neural Networks}
The last (and most complex) model we discuss is a type of neural network
called a \emph{multi-layer perceptron} (see \citealt{Nielsen2015-pu} for
a thorough introduction to neural networks).
%
Neural networks can be understood as a collection of linear models, just
like the one used in logistic regression, arranged in a directed graph.
%
Each node in the graph corresponds to a single linear model, called a
\emph{neuron}, and the edges propagate signals from the input features,
through the neurons, to the output labels.
%
The linear model in each neuron is wrapped in an \emph{activation
  function}, which controls whether (or how strongly) the signal will be
propagated out.
%
These activation functions are what allow neural networks to accurately
model nonlinear functions.
%
A common choice of activation function is the same sigmoid function used
by logistic regression, alternatives include the hyperbolic $\tanh$
function, and more recently the \emph{rectified linear unit} (ReLU),
defined as $f(x) = \mathsf{max}(0,x)$ \citep{Nair2010-xg}.

The neurons are arranged in \emph{layers}; each layer contains a set of
neurons that take in signals from the previous layer and propagate
signals to the next layer.
%
The number of layers, the number of neurons per layer, and the
connections between layers constitute the \emph{architecture} of a
neural network, and are all important hyper-parameters.
%
We consider a particular class of neural networks called
\emph{multi-layer perceptrons} (MLP), where the layers a fully connected to
each other, \ie each neuron propagates its signal to every neuron in the
subsequent layer.
%
We will only consider MLPs with a single layer of neurons, but we will
vary the number of neurons in our experiments.

Neural networks are trained similarly to logistic regression using
stochastic gradient descent, and thus the learning rate $\eta$ and
regularization rate $\lambda$ are also important hyper-parameters.
%
They are, however, much more difficult to train as they require larger
training sets.

Neural networks are popular for their ability to uncover ``hidden''
features in the data.
%
Each neuron learns a different linear combination of the signals from
the previous layer; combined with the activation function this can be
thought of as the neuron learning to respond to a new, \emph{compound}
feature of its inputs.
%
This ability to discover interesting combinations of features makes
neural networks easier to use in some respect; they can reduce the
importance of manual \emph{feature engineering} (selecting interesting
features to provide as inputs).
%
However, the sheer size and complexity of neural networks makes the
model particularly difficult to interpret --- they are generally regarded
as ``black boxes.''
%
Neural networks are also very susceptible to overfitting, so
regularization methods like the $L_2$ norm used for logistic regression
are important.

\ES{should mention that logistic regression can be thought of as a degenerate MLP with 0 layers, and perhaps add a diagram?}

\ES{need to say something about neurons corresponding to ``hidden'' features, give intuition..}

% The fundamental building block of an ANN is the linear model, the
% nonlinearity arises from the \emph{activation functions} that govern
% whether an individual linear model propagates its signal to the next layer.



% ES: keep this at the bottom... sigh
\lstMakeShortInline{|}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
